{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas, xgboost, numpy, textblob, string, re, nltk\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('TEC_ML_ACT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "wb = openpyxl.load_workbook('noChinese1111ValueCounts.xlsx')\n",
    "sheet = wb.active\n",
    "lst=[]\n",
    "for i in range(3,52):\n",
    "    lst.append(sheet.cell(i, 1).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.loc[data['Subject']=='Call']\n",
    "for i in lst:\n",
    "    data1 = data1.append(data.loc[data['Subject']==str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_excel('trainDFwithChinese.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data\n",
    "newdata.drop(newdata.loc[newdata['Subject']=='Call'].index, inplace=True)\n",
    "for i in lst:\n",
    "    newdata.drop(newdata.loc[newdata['Subject']==str(i)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305409"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newdata)+len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.to_excel('testDFwithChinese.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Activity_Id</th>\n",
       "      <th>Type_of_Activity__c</th>\n",
       "      <th>Activity_Type_SFDC__c</th>\n",
       "      <th>Owner_Country__c</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00T6F00002bzw4TUAQ</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>00T6F00002jKce3UAC</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>China</td>\n",
       "      <td>Call</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>00T6F00002lQpA0UAK</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>00T6F00002p1Gg6UAE</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>00T6F00002Sa7D9UAJ</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Activity_Id Type_of_Activity__c Activity_Type_SFDC__c  \\\n",
       "0           0  00T6F00002bzw4TUAQ                Task                  Call   \n",
       "1           2  00T6F00002jKce3UAC                Task                  Call   \n",
       "2           3  00T6F00002lQpA0UAK                Task                  Call   \n",
       "3           5  00T6F00002p1Gg6UAE                Task                  Call   \n",
       "4           6  00T6F00002Sa7D9UAJ                Task                  Call   \n",
       "\n",
       "  Owner_Country__c Subject Description  \n",
       "0         Thailand    Call        Call  \n",
       "1            China    Call        Call  \n",
       "2         Thailand    Call        Call  \n",
       "3         Thailand    Call        Call  \n",
       "4         Thailand    Call        Call  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = pandas.read_excel(\"trainDFwithChinese.xlsx\")\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the reviews data\n",
    "def preprocess_review_data(data,name):\n",
    "    # Proprocessing the data\n",
    "    data[name]=data[name].str.lower()\n",
    "    # Code to remove the Hashtags from the text\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\B#\\S+','',str(x)))\n",
    "    # Code to remove the links from the text\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r\"http\\S+\", \"\", str(x)))\n",
    "    # Code to remove the Special characters from the text \n",
    "    data[name]=data[name].apply(lambda x:' '.join(re.findall(r'\\w+', str(x))))\n",
    "    # Code to substitute the multiple spaces with single spaces\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n",
    "    # Code to remove all the single characters in the text\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "    # Remove the twitter handlers\n",
    "    data[name]=data[name].apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "    \n",
    "    # Function to tokenize and remove the stopwords    \n",
    "def tokenize(data,name):\n",
    "      \n",
    "    def getting(sen):\n",
    "        example_sent = sen\n",
    "\n",
    "        word_tokens = word_tokenize(example_sent) \n",
    "\n",
    "        return word_tokens\n",
    "    \n",
    "    x=[]\n",
    "    for i in data[name].values:\n",
    "        x.append(getting(i))\n",
    "    data[name]=x\n",
    "# Making a function to lemmatize all the words\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def lemmatize_all(data,name):\n",
    "    arr=data[name]\n",
    "    a=[]\n",
    "    for i in arr:\n",
    "        b=[]\n",
    "        for j in i:\n",
    "            x=lemmatizer.lemmatize(j,pos='a')\n",
    "            x=lemmatizer.lemmatize(x)\n",
    "            b.append(x)\n",
    "        a.append(b)\n",
    "    data[name]=a\n",
    "# Function to make it back into a sentence \n",
    "def make_sentences(data,name):\n",
    "    data[name]=data[name].apply(lambda x:' '.join([i+' ' for i in x]))\n",
    "    # Removing double spaces if created\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the preprocessing function to preprocess the tweet data\n",
    "preprocess_review_data(trainDF,'Description')\n",
    "# Using tokenizer and removing the stopwords\n",
    "tokenize(trainDF,'Description')\n",
    "# Converting all the texts back to sentences\n",
    "make_sentences(trainDF,'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['Description'], trainDF['Subject'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:546: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.03585922, 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['Subject'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) \n",
    "\n",
    "xtrain_tfidf_ngram_chars.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, CharLevel Vectors:  0.7612862660558699\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, CharLevel Vectors:  0.8061618611335669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, CharLevel Vectors:  0.8176592113536334\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print(\"Xgb, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Activity_Id</th>\n",
       "      <th>Type_of_Activity__c</th>\n",
       "      <th>Activity_Type_SFDC__c</th>\n",
       "      <th>Owner_Country__c</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>00T6F00002ikD3WUAU</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Trouble shooting</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>00T6F00002wX19dUAC</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NDA discussion</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>00T6F00002y8oA3UAI</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call - Appoint to meet</td>\n",
       "      <td>Call - appoint to demo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>00T6F00002y8oOVUAY</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Email - Intro AccuNest</td>\n",
       "      <td>intro accunest paper_x000D_\\n- brochure_x000D_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>00T6F00002yn5OxUAI</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NDA Review</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Activity_Id Type_of_Activity__c Activity_Type_SFDC__c  \\\n",
       "0           1  00T6F00002ikD3WUAU                Task                  Call   \n",
       "1           9  00T6F00002wX19dUAC                Task                 Email   \n",
       "2          14  00T6F00002y8oA3UAI                Task                  Call   \n",
       "3          15  00T6F00002y8oOVUAY                Task                 Email   \n",
       "4          17  00T6F00002yn5OxUAI                Task                 Email   \n",
       "\n",
       "  Owner_Country__c                 Subject  \\\n",
       "0           Taiwan        Trouble shooting   \n",
       "1           Taiwan          NDA discussion   \n",
       "2         Thailand  Call - Appoint to meet   \n",
       "3         Thailand  Email - Intro AccuNest   \n",
       "4           Taiwan              NDA Review   \n",
       "\n",
       "                                         Description  \n",
       "0                                               Call  \n",
       "1                                              Email  \n",
       "2                             Call - appoint to demo  \n",
       "3  intro accunest paper_x000D_\\n- brochure_x000D_...  \n",
       "4                                              Email  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF = pd.read_excel(\"testDFwithChinese.xlsx\")\n",
    "testDF = testDF.dropna()\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the preprocessing function to preprocess the tweet data\n",
    "preprocess_review_data(testDF,'Description')\n",
    "# Using tokenizer and removing the stopwords\n",
    "tokenize(testDF,'Description')\n",
    "# Converting all the texts back to sentences\n",
    "make_sentences(testDF,'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = testDF['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:36:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Activity_Id</th>\n",
       "      <th>Type_of_Activity__c</th>\n",
       "      <th>Activity_Type_SFDC__c</th>\n",
       "      <th>Owner_Country__c</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Description</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>00T6F00002ikD3WUAU</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Trouble shooting</td>\n",
       "      <td>call</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>00T6F00002wX19dUAC</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NDA discussion</td>\n",
       "      <td>email</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>00T6F00002y8oA3UAI</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call - Appoint to meet</td>\n",
       "      <td>call appoint to demo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>00T6F00002y8oOVUAY</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Email - Intro AccuNest</td>\n",
       "      <td>intro accunest paper_x000d_ brochure_x000d_ co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>00T6F00002yn5OxUAI</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NDA Review</td>\n",
       "      <td>email</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Activity_Id Type_of_Activity__c Activity_Type_SFDC__c  \\\n",
       "0           1  00T6F00002ikD3WUAU                Task                  Call   \n",
       "1           9  00T6F00002wX19dUAC                Task                 Email   \n",
       "2          14  00T6F00002y8oA3UAI                Task                  Call   \n",
       "3          15  00T6F00002y8oOVUAY                Task                 Email   \n",
       "4          17  00T6F00002yn5OxUAI                Task                 Email   \n",
       "\n",
       "  Owner_Country__c                 Subject  \\\n",
       "0           Taiwan        Trouble shooting   \n",
       "1           Taiwan          NDA discussion   \n",
       "2         Thailand  Call - Appoint to meet   \n",
       "3         Thailand  Email - Intro AccuNest   \n",
       "4           Taiwan              NDA Review   \n",
       "\n",
       "                                         Description  Predictions  \n",
       "0                                              call             1  \n",
       "1                                             email            13  \n",
       "2                              call appoint to demo             1  \n",
       "3  intro accunest paper_x000d_ brochure_x000d_ co...            1  \n",
       "4                                             email            13  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    testDF[\"Predictions\"] = predictions\n",
    "\n",
    "# Linear Classifier on Count Vectors\n",
    "predict(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Activity_Id</th>\n",
       "      <th>Type_of_Activity__c</th>\n",
       "      <th>Activity_Type_SFDC__c</th>\n",
       "      <th>Owner_Country__c</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Description</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>00T6F00002ikD3WUAU</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Trouble shooting</td>\n",
       "      <td>call</td>\n",
       "      <td>1</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>00T6F00002wX19dUAC</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NDA discussion</td>\n",
       "      <td>email</td>\n",
       "      <td>13</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>00T6F00002y8oA3UAI</td>\n",
       "      <td>Task</td>\n",
       "      <td>Call</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Call - Appoint to meet</td>\n",
       "      <td>call appoint to demo</td>\n",
       "      <td>1</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>00T6F00002y8oOVUAY</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Email - Intro AccuNest</td>\n",
       "      <td>intro accunest paper_x000d_ brochure_x000d_ co...</td>\n",
       "      <td>1</td>\n",
       "      <td>Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>00T6F00002yn5OxUAI</td>\n",
       "      <td>Task</td>\n",
       "      <td>Email</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NDA Review</td>\n",
       "      <td>email</td>\n",
       "      <td>13</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82746</th>\n",
       "      <td>305388</td>\n",
       "      <td>00U6F00002EOy3GUAT</td>\n",
       "      <td>Event</td>\n",
       "      <td>Visit</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>拜訪H棟開刀房志豪護理長</td>\n",
       "      <td>visit</td>\n",
       "      <td>47</td>\n",
       "      <td>Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82747</th>\n",
       "      <td>305389</td>\n",
       "      <td>00U6F00002EOy3LUAT</td>\n",
       "      <td>Event</td>\n",
       "      <td>Visit</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>拜訪醫工林康慈先生</td>\n",
       "      <td>visit</td>\n",
       "      <td>47</td>\n",
       "      <td>Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82748</th>\n",
       "      <td>305390</td>\n",
       "      <td>00U6F00002EOYfCUAX</td>\n",
       "      <td>Event</td>\n",
       "      <td>Visit</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>拜訪供應中心芷芸學姊</td>\n",
       "      <td>visit</td>\n",
       "      <td>47</td>\n",
       "      <td>Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82749</th>\n",
       "      <td>305391</td>\n",
       "      <td>00U6F00002EOYfXUAX</td>\n",
       "      <td>Event</td>\n",
       "      <td>Visit</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>拜訪醫工林康慈先生</td>\n",
       "      <td>visit</td>\n",
       "      <td>47</td>\n",
       "      <td>Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82750</th>\n",
       "      <td>305407</td>\n",
       "      <td>00U90000012FXpHEAW</td>\n",
       "      <td>Event</td>\n",
       "      <td>Other</td>\n",
       "      <td>China</td>\n",
       "      <td>技术交流</td>\n",
       "      <td>other</td>\n",
       "      <td>28</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82726 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         Activity_Id Type_of_Activity__c  \\\n",
       "0               1  00T6F00002ikD3WUAU                Task   \n",
       "1               9  00T6F00002wX19dUAC                Task   \n",
       "2              14  00T6F00002y8oA3UAI                Task   \n",
       "3              15  00T6F00002y8oOVUAY                Task   \n",
       "4              17  00T6F00002yn5OxUAI                Task   \n",
       "...           ...                 ...                 ...   \n",
       "82746      305388  00U6F00002EOy3GUAT               Event   \n",
       "82747      305389  00U6F00002EOy3LUAT               Event   \n",
       "82748      305390  00U6F00002EOYfCUAX               Event   \n",
       "82749      305391  00U6F00002EOYfXUAX               Event   \n",
       "82750      305407  00U90000012FXpHEAW               Event   \n",
       "\n",
       "      Activity_Type_SFDC__c Owner_Country__c                 Subject  \\\n",
       "0                      Call           Taiwan        Trouble shooting   \n",
       "1                     Email           Taiwan          NDA discussion   \n",
       "2                      Call         Thailand  Call - Appoint to meet   \n",
       "3                     Email         Thailand  Email - Intro AccuNest   \n",
       "4                     Email           Taiwan              NDA Review   \n",
       "...                     ...              ...                     ...   \n",
       "82746                 Visit           Taiwan            拜訪H棟開刀房志豪護理長   \n",
       "82747                 Visit           Taiwan               拜訪醫工林康慈先生   \n",
       "82748                 Visit           Taiwan              拜訪供應中心芷芸學姊   \n",
       "82749                 Visit           Taiwan               拜訪醫工林康慈先生   \n",
       "82750                 Other            China                    技术交流   \n",
       "\n",
       "                                             Description  Predictions  label  \n",
       "0                                                  call             1   Call  \n",
       "1                                                 email            13  Email  \n",
       "2                                  call appoint to demo             1   Call  \n",
       "3      intro accunest paper_x000d_ brochure_x000d_ co...            1   Call  \n",
       "4                                                 email            13  Email  \n",
       "...                                                  ...          ...    ...  \n",
       "82746                                             visit            47  Visit  \n",
       "82747                                             visit            47  Visit  \n",
       "82748                                             visit            47  Visit  \n",
       "82749                                             visit            47  Visit  \n",
       "82750                                             other            28  Other  \n",
       "\n",
       "[82726 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF['label']=encoder.inverse_transform(testDF['Predictions'])\n",
    "testDF"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
